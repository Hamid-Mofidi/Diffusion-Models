{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQ3XfMApupiNHCaWv0UaUh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamid-Mofidi/Diffusion-Models/blob/main/Generative_Models/Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generative Models:**\n",
        "\n",
        "A generative model is a type of machine learning model that learns the distribution of the data and can generate new data similar to the original data.\n",
        "\n",
        "In generative models, we want to make a model that can generate realistic samples that are similar to a given data distribution, such as images of faces, handwritten digits, etc. We need to train our model using some data samples that have not been seen before.\n",
        "\n",
        "Different generative models work differently, but they all **try to learn** some representation of the data distribution that can be used for sampling.\n",
        "\n",
        "\n",
        "#### **Discriminative vs Generative Models:**\n",
        "\n",
        "Discriminative models learn the boundary between classes or labels in a dataset, while generative models learn the distribution of the data points in each class or label.\n",
        "\n",
        " Discriminative models use conditional probability to make predictions, such as P(Y|X), where Y is the output and X is the input. Generative models use joint probability to model the data, such as P(X,Y), where X and Y are both random variables.\n",
        "\n",
        "**The advantages and disadvantages:**\n",
        "\n",
        " Discriminative models are usually computationally cheaper and more accurate for classification or regression tasks, as they focus on solving the actual problem directly. Generative models are usually more complex and less accurate for classification or regression tasks, as they solve a more general problem first. However, Generative models can also be used to generate new data points or predict what occurs next in a sequence, as they capture the underlying structure of the data. Discriminative models cannot do that, as they only learn the differences between classes or labels.\n",
        "\n",
        "\n",
        " **Some examples of discriminative models are:**\n",
        "\n",
        "k-nearest neighbors (k-NN),  Logistic regression,  Support Vector Machines (SVMs),  Decision Trees,  Random Forest,  Artificial Neural Networks (ANNs)\n",
        "\n",
        "**Some examples of generative models are:**\n",
        "\n",
        " Naive Bayes Classifier,  Generative Adversarial Networks (GANs), Gaussian Mixture Model, Hidden Markov Model, Probabilistic context-free grammar.\n",
        "\n",
        "\n",
        " **Example:** I clarify the two models by a simple mathematical example. Let's say we have a dataset of animal features and labels, such as:\n",
        "\n",
        "| Features | Label |\n",
        "|----------|-------|\n",
        "| Fur, 4 legs, tail | Cat |\n",
        "| Fur, 4 legs, tail | Dog |\n",
        "| Feathers, 2 legs, beak | Bird |\n",
        "| Scales, no legs, tail | Snake |\n",
        "\n",
        "A generative model would learn the joint probability distribution of the features and the labels, such as P(Fur, 4 legs, tail, Cat) or P(Feathers, 2 legs, beak, Bird). It would then use the Bayes' rule to calculate the conditional probability of the label given the features, such as P(Cat | Fur, 4 legs, tail) or P(Bird | Feathers, 2 legs, beak).\n",
        "\n",
        "A discriminative model would learn the conditional probability distribution of the label given the features directly, such as P(Cat | Fur, 4 legs, tail) or P(Bird | Feathers, 2 legs, beak). It would not care about the joint probability distribution of the features and the labels.\n",
        "\n",
        "A generative model can be seen as a two-step process, where it first learns how the data is generated and then makes predictions based on that. A discriminative model can be seen as a one-step process, where it directly learns how to make predictions from the data.\n",
        "\n",
        "\n",
        "\n",
        "**There is no definitive list of all the generative models, as different sources may classify them differently. However, one possible way to organize them is as follows:**\n",
        "\n",
        "•  **Mixture models:** Generative models that assume the data is generated by a mixture of components, each with its own probability distribution. Examples are Gaussian mixture models, latent Dirichlet allocation, and topic models.\n",
        "\n",
        "•  **Bayesian networks:** Generative models that represent the joint probability distribution of a set of variables using a directed acyclic graph. Examples are naive Bayes, Bayesian belief networks, and hidden Markov models.\n",
        "\n",
        "•  **Boltzmann machines:** Generative models that represent the joint probability distribution of a set of binary variables using an undirected graph. Examples are restricted Boltzmann machines, deep belief networks, and deep Boltzmann machines.\n",
        "\n",
        "•  **Autoencoders:** Generative models that consist of two neural networks: an encoder that maps the data to a latent space and a decoder that reconstructs the data from the latent space. Examples are variational autoencoders, denoising autoencoders, and sparse autoencoders.\n",
        "\n",
        "•  **Generative adversarial networks:** Generative models that consist of two neural networks: a generator that tries to produce realistic data and a discriminator that tries to distinguish between real and fake data. Examples are vanilla GANs, conditional GANs, and cycle GANs.\n",
        "\n",
        "•  **Diffusion probabilistic models:** Generative models that model the data as a diffusion process, where the data is gradually corrupted by noise until it becomes random. To generate new data, they reverse the diffusion process, starting from noise and gradually denoising it until it becomes realistic. Examples are denoising diffusion probabilistic models, noise conditioned score networks, and stochastic differential equations.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BXjIZYNqRWo2"
      }
    }
  ]
}